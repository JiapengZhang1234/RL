{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Conv2D,Flatten\n",
    "\n",
    "#from keras.layers import MaxPooling2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork:\n",
    "    def __init__(\n",
    "                 self,\n",
    "                 n_actions,\n",
    "                 learning_rate=0.01,\n",
    "                 reward_decay=0.9,\n",
    "                 e_greedy=0.9,\n",
    "                 replay_target_iter=300,\n",
    "                 memory_size=500,\n",
    "                 batch_size=32\n",
    "                 ):\n",
    "        self.n_actions = n_actions\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #bulid eval network and target network\n",
    "        self.eval_net = self._build_net()\n",
    "        self.target_net = self._build_net()\n",
    "        \n",
    "        #build replay buffer\n",
    "        self.memory = deque(maxlen=self.memory_size)\n",
    "        \n",
    "        #frequency of updating target network\n",
    "        self.learning_step_counter = 0\n",
    "        self.replay_target_iter = replay_target_iter\n",
    "        \n",
    "        \n",
    "    \n",
    "    # build network fun\n",
    "    def _build_net(self):\n",
    "        #build sequential model\n",
    "        model = Sequential()\n",
    "        \n",
    "        #add convolution layers\n",
    "        model.add(Conv2D(32,(8,8),strides=(4,4),activation='relu',\n",
    "                 input_shape=(84,84,3)))\n",
    "        model.add(Conv2D(64,(4,4),strides=(2,2),activation='relu'\n",
    "                  ))\n",
    "        model.add(Conv2D(64,(3,3),strides=(1,1),activation='relu'\n",
    "                  ))\n",
    "        \n",
    "        #data compression\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        #build first dense layer\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        #bulid output layer\n",
    "        model.add(Dense(self.n_actions,activation='linear'))\n",
    "        \n",
    "        #model optimization\n",
    "        model.compile(loss='mse', optimizer='RMSprop')\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    # target network para update fun\n",
    "    def target_net_para_setting(self,eval_n,target_n):\n",
    "        target_n.set_weights(\n",
    "            eval_n.get_weights()\n",
    "            )\n",
    "        \n",
    "    # store transition fun\n",
    "    def store_transition_in_memory(self,s,a,r,s_,done):\n",
    "        self.memory.append((s,a,r,s_,done))\n",
    "    \n",
    "    \n",
    "    # choose action according state fun\n",
    "    def choose_action(self,state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action_values = self.eval_net.predict(state)\n",
    "            action =  np.argmax(action_values[0]) #返回最大值的列索引，即动作名\n",
    "        else:\n",
    "            action = np.random.choice(self.n_actions)\n",
    "        return action\n",
    "    \n",
    "    # learn fun\n",
    "    def learn(self):\n",
    "        # Data Sample        \n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        \n",
    "        # eval network update\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            if done:\n",
    "                q_target_s_a = reward\n",
    "            else:\n",
    "                q_target_s_a = reward + self.gamma * np.max(\n",
    "                    self.target_net.predict(next_state))\n",
    "            \n",
    "            q_eval = self.eval_net.predict(state)\n",
    "            q_predict_s_a = q_eval[0][action]\n",
    "            q_predict_s_a += self.lr * (q_target_s_a - q_predict_s_a)\n",
    "            q_eval[0][action] =  q_predict_s_a\n",
    "            \n",
    "            self.eval_net.fit(state,q_eval)\n",
    "            self.learning_step_counter += 1\n",
    "        \n",
    "        # target network update\n",
    "        if self.learning_step_counter % self.replay_target_iter == 0:\n",
    "            self.target_net_para_setting(self.eval_net,self.target_net)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space : Discrete(4)\n",
      "observation space : Box(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "# 环境\n",
    "env = gym.make('Breakout-v0')\n",
    "print('action space :',env.action_space)\n",
    "print('observation space :',env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 智能体\n",
    "RL = DeepQNetwork(n_actions=env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RL.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0xebe3860>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RL.eval_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 84, 84, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RL.eval_net.input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "observation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = cv2.resize(src=observation, dsize=(84,84))\n",
    "observation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(observation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = np.expand_dims(observation,axis=0) #,len(observation.shape)\n",
    "observation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = RL.choose_action(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_, reward, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ale.lives': 5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_ = cv2.resize(src=observation_,dsize=(84,84))\n",
    "observation_ = np.expand_dims(observation_,axis=0)\n",
    "observation_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL.store_transition_in_memory(observation,action,reward,observation_,done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(array([[[[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                ...,\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]]]], dtype=uint8),\n",
       "        3,\n",
       "        0.0,\n",
       "        array([[[[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                ...,\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]],\n",
       "        \n",
       "                [[0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 ...,\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0],\n",
       "                 [0, 0, 0]]]], dtype=uint8),\n",
       "        False)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RL.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
